tn <- states[states$NAME_1 == 'Tennessee',]
plot(tn)
#Tennessee elevation
tn_elev <- crop(usa[[1]], tn)
plot(tn_elev)
#Mask the non-Tennessee parts
tn_elev <- mask(tn_elev, tn)
plot(tn_elev)
shiny::runApp('Documents/datalab/data_entry')
library(shiny)
library(tidyverse)
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
# Define UI for application that draws a histogram
ui <- fluidPage(
titlePanel('The Food and The Furious: Dining Activity Trends in Sewanee'),
fluidRow(column(6, 'first row first column'),
column(6, 'first row second column')),
fluidRow(column(6, 'second row, first column'),
column(6, 'second row, second column'))
)
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
runApp('Documents/datalab/data_entry')
library(shiny)
library(tidyverse)
read.csv('https://docs.google.com/spreadsheets/d/161MfIHC-6iwkpx85Ce2-zV52F4LNET2sOhgl0_zl3kM/edit?usp=sharing')
runApp('Documents/datalab/fake_fencing')
runApp('Documents/datalab/fake_fencing')
runApp('Documents/datalab/fake_fencing')
runApp('Documents/datalab/fake_fencing')
runApp('Documents/datalab/fake_fencing')
runApp('Documents/datalab/fake_fencing')
shiny::runApp('Documents/datalab/fake_fencing')
runApp('Documents/datalab/fake_fencing')
runApp('Documents/datalab/fake_fencing')
runApp('Documents/datalab/fake_fencing')
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
bats <- readRDS('bats.RData')
bats <- bats %>%
mutate(year = year(DATE),
monthN = month(DATE),
month = month.abb[monthN],
hour = hour(TIME) )
# Any bat listed as CORROW should be listed as the secondary species
bats <- bats %>%
mutate( AUTO.ID = gsub("CORROW",
unlist(strsplit(ALTERNATES, split=';', fixed=TRUE))[1],
AUTO.ID) )
# Chunk 2
# species call counts by year -----
No.ID <- c('NoId', 'NoID', 'Noise')
bats.time <- bats %>%
filter(! AUTO.ID %in% No.ID, year < 2022) %>%
group_by(year, AUTO.ID) %>%
tally()
ggplot(data=bats.time, aes(x=year, y=n, color=AUTO.ID) )+
geom_line()+
labs(title = 'Number of Total Calls Per Species',
subtitle = "From 2017-2021",
x = 'Year', y = 'Number of Calls')
# Chunk 3
# my goal is to group everything and then use summarize so that I can have the total frequency of the bats by species across months.
freq_by_month <- bats %>%
group_by(year, monthN, AUTO.ID) %>%
filter(! AUTO.ID %in% No.ID) %>%
summarize(frequencies = n())
# With the graph, I want to filter to keep only specific year and species combinations for clarity, and I want months to be on the x-axis and the number of calls recorded on the y.
chosen_species <- levels(factor(freq_by_month$AUTO.ID))
ggplot(data = freq_by_month %>% filter(AUTO.ID %in% chosen_species, year == 2017),
aes(x = monthN,
y = frequencies,
color = AUTO.ID))+
geom_line()
# now I want to see what the overall frequency of recordings are over the hours of the day in december
freq_hour_12 <- bats %>%
group_by(monthN, hour, AUTO.ID) %>%
filter(! AUTO.ID %in% No.ID) %>%
filter(monthN == 12) %>%
summarize(frequencies = n())
ggplot(data = freq_hour_12,
aes(x = hour,
y = frequencies,
color = AUTO.ID))+
geom_line()+
labs(title = "Frequency of Bat Species during December",
subtitle = "Totaled from 2017-2021",
x = "Hour of Day",
y = "Call Frequency")
library(tidyverse)
library(lubridate)
bats <- readRDS('bats.RData')
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
#library(ggthemes)
#library(gsheet)
library(readxl)
library(lubridate)
library(hms)
#library(tidytext)
fixDates <- function( date ){
for(i in 1:length(date) ){
if( grepl('/',date[i]) ){
dt <- unlist(strsplit(date[i],split='/'))
date[i] <- paste0(dt[3],"-",dt[1],"-",dt[2])
}
}
return(date)
}
# Chunk 2
# get all file path names in Data folder -----
files <- paste0('Data/',dir('Data/',recursive=TRUE))
# filter out non-data files -----
files <- data.frame(files) %>%
filter( grepl("Compartment",files) )
# get the path names of all the raw data files -----
files.data <- files %>%
filter( !grepl("idsummary",files), grepl(".csv$|.xls$|.xlsx$",files) )
# get the path names of all the summary data files -----
files.summaries <- files %>%
filter( grepl("idsummary",files) )
# get the path names of all the other files -----
files.other <- files %>%
filter( !grepl("idsummary",files), !grepl(".csv$|.xls$|.xlsx$",files) )
# Chunk 3
# reading in the data -----
# variables to keep
standard <- c('AUTO.ID', 'DATE', 'TIME','LONGITUDE','LATITUDE')
# LONGITUDE and LATITUDE are not in all of them; HOUR can be taken from TIME
merges <- c('ALTERNATES','ALTERNATE.1','ALTERNATE.2')
# empty data frame to hold the data
bats <- data.frame()
# for every file path in the data.files set...
for(file in files.data$files){
# let us know what file it's working on
message(file)
# set 'vars' to be an empty vector (for the variable names)
vars <- c()
# set 'temp' to be an empty data frame (for the data)
temp <- data.frame()
# if the file is a csv, try read_csv
if( grepl('.csv',file) ){
try( temp <- read_csv(file, show_col_types=FALSE) )
}
#if it's an excel, try read_excel
if( grepl('.xls|.xlsx',file) ){
try( temp <- read_excel(file) )
}
# if we accidentally read in a summary file, reset 'temp' to an empty data frame
if( length(temp)>0 & grepl("KALEIDOSCOPE", paste(names(temp),sep='',collapse=' ')) ){
temp <- data.frame()
}
# if we got data from the reads...
if( length(temp)>0 ){  # (aka if 'temp' has columns)
if( nrow(temp[1])>1 ){ # (and the columns have entries)
# change variable names to uppercase
names(temp) <- toupper(names(temp))
# clean up the formatting
names(temp) <- gsub(" ",".",names(temp))
names(temp) <- gsub("-",".",names(temp))
names(temp) <- gsub("*","",names(temp))
names(temp) <- gsub("AUTO.ID.","AUTO.ID",names(temp))
# get the cleaned variable names
vars <- names(temp)
# collapse the vector into a single string
vars <- paste(vars,sep='',collapse=' ')
# check if it has ALTERNATE.1 and ALTERNATE.2
if( grepl('ALTERNATE.1',vars) & grepl('ALTERNATE.1',vars) ){
temp <- temp %>%
mutate( ALTERNATES = paste(c(ALTERNATE.1,ALTERNATE.2),sep='',collapse=';') )
}#--end alternates 1 and 2 check ---
# check if it doesn't have ALTERNATES
if( !grepl('ALTERNATES',vars) ){
temp['ALTERNATES'] <- NA
}#--end missing alternates var creation--
# for each standard variable we need...
for(var in standard){
# check to make sure it's in the variables string
# if any given one is missing, make an empty column for it
if( !grepl(var, vars) ){ temp[var] <- NA }
}#--end standard var check loop--
# select only the variables we want
temp <- temp %>% select(AUTO.ID, DATE, TIME, ALTERNATES, LATITUDE, LONGITUDE)
# make sure DATE and TIME are in the proper format
temp <- temp %>% mutate( DATE = as.character(DATE), TIME = as_hms(TIME),
DATE = gsub('2000','2022',DATE, fixed=TRUE),
DATE = as.Date(fixDates(DATE)) )
# break the file path up by '/'s
C_S <- unlist( strsplit(file, split = "/") )
#get the index of the piece that contains 'Compartment'
idx <- which(grepl("Compartment",C_S))
# if it's the Compartment 22-Firelane folder...
if( grepl("Firelane", C_S[ idx ], ignore.case=TRUE) ){
# get the portion that contains 'Compartment'
C_S <- C_S[idx]
# break it up by '-' (so it makes "Compartment 22" and "Firelane")
C_S <- unlist( strsplit(C_S, split="-") )
# record compartment and change 'Compartment 22' into 'C22'
compartment <- gsub("Compartment ","C",C_S[1],ignore.case=TRUE)
# record the site (which will be 'Firelane')
site <- C_S[2]
}
# otherwise, if it's a standard compartment...
else {
# get the portion after the one that contains 'Compartment'
C_S <- C_S[ idx+1 ]
# break up by '_', since the standard format is C#_S#
C_S <- unlist( strsplit(C_S, split="_") )
# record compartment
compartment <- C_S[1]
# record site
site <- C_S[2]
}
# replace all the P# sites with S# sites
#site <- gsub("P","S",site)
# if there's a space (like from 'C53_P1 (S4Z00723)') keep only the first bit
if( grepl(" ",site) ){ site <- unlist( strsplit(site, split=' ') )[1] }
# if site is just a number and not 'Firelane'...
if( !grepl("S|P",site) & !grepl("Firelane",site,ignore.case=TRUE) ){
# put an 'S' in front of it
site <- paste0('S',site)
}
# add them to the data set
temp['COMPARTMENT'] <- compartment
temp['SITE'] <- site
# record the file path to original data
# in case we find something wacky we want to look into
temp['path'] <- file
# combine the current data set with the overall data set
bats <- rbind( bats, temp )
}}#--end temp not null checks--
}#--end big loop--
#write.csv(bats, file='bats.csv')
saveRDS(bats, file='bats.RData')
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
#library(ggthemes)
#library(gsheet)
library(readxl)
library(lubridate)
library(hms)
#library(tidytext)
fixDates <- function( date ){
for(i in 1:length(date) ){
if( grepl('/',date[i]) ){
dt <- unlist(strsplit(date[i],split='/'))
date[i] <- paste0(dt[3],"-",dt[1],"-",dt[2])
}
}
return(date)
}
# Chunk 2
# get all file path names in Data folder -----
files <- paste0('Data/',dir('Data/',recursive=TRUE))
# filter out non-data files -----
files <- data.frame(files) %>%
filter( grepl("Compartment",files) )
# get the path names of all the raw data files -----
files.data <- files %>%
filter( !grepl("idsummary",files), grepl(".csv$|.xls$|.xlsx$",files) )
# get the path names of all the summary data files -----
files.summaries <- files %>%
filter( grepl("idsummary",files) )
# get the path names of all the other files -----
files.other <- files %>%
filter( !grepl("idsummary",files), !grepl(".csv$|.xls$|.xlsx$",files) )
# Chunk 3
# reading in the data -----
# variables to keep
standard <- c('AUTO.ID', 'DATE', 'TIME','LONGITUDE','LATITUDE')
# LONGITUDE and LATITUDE are not in all of them; HOUR can be taken from TIME
merges <- c('ALTERNATES','ALTERNATE.1','ALTERNATE.2')
# empty data frame to hold the data
bats <- data.frame()
# for every file path in the data.files set...
for(file in files.data$files){
# let us know what file it's working on
message(file)
# set 'vars' to be an empty vector (for the variable names)
vars <- c()
# set 'temp' to be an empty data frame (for the data)
temp <- data.frame()
# if the file is a csv, try read_csv
if( grepl('.csv',file) ){
try( temp <- read_csv(file, show_col_types=FALSE) )
}
#if it's an excel, try read_excel
if( grepl('.xls|.xlsx',file) ){
try( temp <- read_excel(file) )
}
# if we accidentally read in a summary file, reset 'temp' to an empty data frame
if( length(temp)>0 & grepl("KALEIDOSCOPE", paste(names(temp),sep='',collapse=' ')) ){
temp <- data.frame()
}
# if we got data from the reads...
if( length(temp)>0 ){  # (aka if 'temp' has columns)
if( nrow(temp[1])>1 ){ # (and the columns have entries)
# change variable names to uppercase
names(temp) <- toupper(names(temp))
# clean up the formatting
names(temp) <- gsub(" ",".",names(temp))
names(temp) <- gsub("-",".",names(temp))
names(temp) <- gsub("*","",names(temp))
names(temp) <- gsub("AUTO.ID.","AUTO.ID",names(temp))
# get the cleaned variable names
vars <- names(temp)
# collapse the vector into a single string
vars <- paste(vars,sep='',collapse=' ')
# check if it has ALTERNATE.1 and ALTERNATE.2
if( grepl('ALTERNATE.1',vars) & grepl('ALTERNATE.1',vars) ){
temp <- temp %>%
mutate( ALTERNATES = paste(c(ALTERNATE.1,ALTERNATE.2),sep='',collapse=';') )
}#--end alternates 1 and 2 check ---
# check if it doesn't have ALTERNATES
if( !grepl('ALTERNATES',vars) ){
temp['ALTERNATES'] <- NA
}#--end missing alternates var creation--
# for each standard variable we need...
for(var in standard){
# check to make sure it's in the variables string
# if any given one is missing, make an empty column for it
if( !grepl(var, vars) ){ temp[var] <- NA }
}#--end standard var check loop--
# select only the variables we want
temp <- temp %>% select(AUTO.ID, DATE, TIME, ALTERNATES, LATITUDE, LONGITUDE)
# make sure DATE and TIME are in the proper format
temp <- temp %>% mutate( DATE = as.character(DATE), TIME = as_hms(TIME),
DATE = gsub('2000','2022',DATE, fixed=TRUE),
DATE = as.Date(fixDates(DATE)) )
# break the file path up by '/'s
C_S <- unlist( strsplit(file, split = "/") )
#get the index of the piece that contains 'Compartment'
idx <- which(grepl("Compartment",C_S))
# if it's the Compartment 22-Firelane folder...
if( grepl("Firelane", C_S[ idx ], ignore.case=TRUE) ){
# get the portion that contains 'Compartment'
C_S <- C_S[idx]
# break it up by '-' (so it makes "Compartment 22" and "Firelane")
C_S <- unlist( strsplit(C_S, split="-") )
# record compartment and change 'Compartment 22' into 'C22'
compartment <- gsub("Compartment ","C",C_S[1],ignore.case=TRUE)
# record the site (which will be 'Firelane')
site <- C_S[2]
}
# otherwise, if it's a standard compartment...
else {
# get the portion after the one that contains 'Compartment'
C_S <- C_S[ idx+1 ]
# break up by '_', since the standard format is C#_S#
C_S <- unlist( strsplit(C_S, split="_") )
# record compartment
compartment <- C_S[1]
# record site
site <- C_S[2]
}
# replace all the P# sites with S# sites
#site <- gsub("P","S",site)
# if there's a space (like from 'C53_P1 (S4Z00723)') keep only the first bit
if( grepl(" ",site) ){ site <- unlist( strsplit(site, split=' ') )[1] }
# if site is just a number and not 'Firelane'...
if( !grepl("S|P",site) & !grepl("Firelane",site,ignore.case=TRUE) ){
# put an 'S' in front of it
site <- paste0('S',site)
}
# add them to the data set
temp['COMPARTMENT'] <- compartment
temp['SITE'] <- site
# record the file path to original data
# in case we find something wacky we want to look into
temp['path'] <- file
# combine the current data set with the overall data set
bats <- rbind( bats, temp )
}}#--end temp not null checks--
}#--end big loop--
#write.csv(bats, file='bats.csv')
saveRDS(bats, file='bats.RData')
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
#library(ggthemes)
#library(gsheet)
library(readxl)
library(lubridate)
library(hms)
#library(tidytext)
# Chunk 2
# get all file path names in Data folder -----
files <- paste0('Data/',dir('Data/',recursive=TRUE))
# filter out non-data files -----
files <- data.frame(files) %>%
filter( grepl("Compartment",files) )
# get the path names of all the raw data files -----
files.data <- files %>%
filter( !grepl("idsummary",files), grepl(".csv$|.xls$|.xlsx$",files) )
# get the path names of all the summary data files -----
files.summaries <- files %>%
filter( grepl("idsummary",files) )
# get the path names of all the other files -----
files.other <- files %>%
filter( !grepl("idsummary",files), !grepl(".csv$|.xls$|.xlsx$",files) )
# Chunk 7
# recording compartment and site test -----
files.CS <- data.frame()
for(file in files.data$files){
C_S <- unlist( strsplit(file, split = "/") )
if( grepl("Firelane", C_S[which(grepl("Compartment",C_S))], ignore.case=TRUE) ){
C_S <- C_S[ which(grepl("Compartment",C_S,ignore.case=TRUE)) ]
C_S <- unlist( strsplit(C_S, split="-") )
compartment <- gsub("Compartment ","C",C_S[1],ignore.case=TRUE)
site <- C_S[2]
}
else {
C_S <- C_S[ which(grepl("Compartment",C_S))+1 ]
C_S <- unlist( strsplit(C_S, split="_") )
compartment <- C_S[1]
site <- C_S[2]
}
site <- gsub("P","S",site)
if( grepl(" ",site) ){
site <- unlist( strsplit(site, split=' ') )[1]
}
if( !grepl("S",site) & !grepl("Firelane",site,ignore.case=TRUE) ){
site <- paste0('S',site)
}
files.CS <- rbind(files.CS, data.frame(file,compartment,site))
}
bats <- readRDS('bats.RData')
setwd("~/Documents")
setwd("~/Documents/datalab/bats")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
bats <- readRDS('bats.RData')
bats <- bats %>%
mutate(year = year(DATE),
monthN = month(DATE),
month = month.abb[monthN],
hour = hour(TIME) )
# Any bat listed as CORROW should be listed as the secondary species
bats <- bats %>%
mutate( AUTO.ID = gsub("CORROW",
unlist(strsplit(ALTERNATES, split=';', fixed=TRUE))[1],
AUTO.ID) )
# Chunk 2
# species call counts by year -----
No.ID <- c('NoId', 'NoID', 'Noise')
bats.time <- bats %>%
filter(! AUTO.ID %in% No.ID, year < 2022) %>%
group_by(year, AUTO.ID) %>%
tally()
ggplot(data=bats.time, aes(x=year, y=n, color=AUTO.ID) )+
geom_line()+
labs(title = 'Number of Total Calls Per Species',
subtitle = "From 2017-2021",
x = 'Year', y = 'Number of Calls')
# Chunk 3
# my goal is to group everything and then use summarize so that I can have the total frequency of the bats by species across months.
freq_by_month <- bats %>%
group_by(year, monthN, AUTO.ID) %>%
filter(! AUTO.ID %in% No.ID) %>%
summarize(frequencies = n())
# With the graph, I want to filter to keep only specific year and species combinations for clarity, and I want months to be on the x-axis and the number of calls recorded on the y.
chosen_species <- levels(factor(freq_by_month$AUTO.ID))
ggplot(data = freq_by_month %>% filter(AUTO.ID %in% chosen_species, year == 2017),
aes(x = monthN,
y = frequencies,
color = AUTO.ID))+
geom_line()
# now I want to see what the overall frequency of recordings are over the hours of the day in december
freq_hour_12 <- bats %>%
group_by(monthN, hour, AUTO.ID) %>%
filter(! AUTO.ID %in% No.ID) %>%
filter(monthN == 12) %>%
summarize(frequencies = n())
ggplot(data = freq_hour_12,
aes(x = hour,
y = frequencies,
color = AUTO.ID))+
geom_line()+
labs(title = "Frequency of Bat Species during December",
subtitle = "Totaled from 2017-2021",
x = "Hour of Day",
y = "Call Frequency")
